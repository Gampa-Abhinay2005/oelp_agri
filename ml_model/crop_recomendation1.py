# -*- coding: utf-8 -*-
"""crop_recomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MTEeI55_ThrLs4ipRCtGo8rA-rhcpzPO
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import os

crop_df=pd.read_csv('ml_model/data_core.csv')

# crop_df.head()

# crop_df.isnull().sum()

from sklearn.preprocessing import LabelEncoder, MinMaxScaler

# Encode categorical variables and store mappings
label_encoder = LabelEncoder()

# Soil Type mapping
crop_df['Soil Type'] = label_encoder.fit_transform(crop_df['Soil Type'])
soil_type_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}

# Crop Type mapping
crop_df['Crop Type'] = label_encoder.fit_transform(crop_df['Crop Type'])
crop_type_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}

# Fertilizer Name mapping
crop_df['Fertilizer Name'] = label_encoder.fit_transform(crop_df['Fertilizer Name'])
fertilizer_name_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}

# Normalize numerical features
scaler = MinMaxScaler()
numerical_columns = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']
crop_df[numerical_columns] = scaler.fit_transform(crop_df[numerical_columns])

# Display the first few rows of the preprocessed data
crop_df.head()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Define features (X) and target variables (y)
X = crop_df[numerical_columns + ['Soil Type']]
y_crop = crop_df['Crop Type']
y_fertilizer = crop_df['Fertilizer Name']

# Split the data into training and testing sets
X_train, X_test, y_crop_train, y_crop_test = train_test_split(X, y_crop, test_size=0.2, random_state=42)
_, _, y_fertilizer_train, y_fertilizer_test = train_test_split(X, y_fertilizer, test_size=0.2, random_state=42)

# Train a Random Forest model for Crop Type prediction
crop_model = RandomForestClassifier(random_state=42)
crop_model.fit(X_train, y_crop_train)

# Train a Random Forest model for Fertilizer Name prediction
fertilizer_model = RandomForestClassifier(random_state=42)
fertilizer_model.fit(X_train, y_fertilizer_train)

# Evaluate the Crop Type model
y_crop_pred = crop_model.predict(X_test)
print("Crop Type Prediction:")
print(classification_report(y_crop_test, y_crop_pred))
print("Accuracy:", accuracy_score(y_crop_test, y_crop_pred))

# Evaluate the Fertilizer Name model
y_fertilizer_pred = fertilizer_model.predict(X_test)
print("Fertilizer Name Prediction:")
print(classification_report(y_fertilizer_test, y_fertilizer_pred))
print("Accuracy:", accuracy_score(y_fertilizer_test, y_fertilizer_pred))

from sklearn.model_selection import GridSearchCV

# Split the training data into training and validation sets
X_train_final, X_val, y_crop_train_final, y_crop_val = train_test_split(X_train, y_crop_train, test_size=0.2, random_state=42)

# Define the parameter grid for Random Forest
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Perform Grid Search with cross-validation
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                           param_grid=param_grid,
                           cv=3,
                           scoring='accuracy',
                           verbose=2,
                           n_jobs=-1)

grid_search.fit(X_train_final, y_crop_train_final)

# Get the best parameters and train the final model
best_params = grid_search.best_params_
print("Best Parameters:", best_params)

# Train the final model with the best parameters
final_crop_model = RandomForestClassifier(random_state=42, **best_params)
final_crop_model.fit(X_train_final, y_crop_train_final)

# Evaluate the model on the validation set
y_crop_val_pred = final_crop_model.predict(X_val)
print("Validation Set Performance:")
print(classification_report(y_crop_val, y_crop_val_pred))
print("Accuracy:", accuracy_score(y_crop_val, y_crop_val_pred))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

# Convert target variable to categorical (one-hot encoding)
y_crop_train_final_categorical = to_categorical(y_crop_train_final)
y_crop_val_categorical = to_categorical(y_crop_val)

# Define the neural network model
model = Sequential([
    Dense(128, input_dim=X_train_final.shape[1], activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y_crop_train_final_categorical.shape[1], activation='softmax')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train_final, y_crop_train_final_categorical,
                    validation_data=(X_val, y_crop_val_categorical),
                    epochs=50,
                    batch_size=32,
                    verbose=2)

# Evaluate the model on the validation set
val_loss, val_accuracy = model.evaluate(X_val, y_crop_val_categorical, verbose=0)
print(f"Validation Accuracy: {val_accuracy:.4f}")

from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV

# Define the parameter grid for XGBoost
param_dist = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7, 10],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

# Initialize the XGBoost classifier
xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')

# Perform Randomized Search with cross-validation
random_search = RandomizedSearchCV(estimator=xgb_model,
                                   param_distributions=param_dist,
                                   n_iter=50,
                                   scoring='accuracy',
                                   cv=3,
                                   verbose=2,
                                   n_jobs=-1,
                                   random_state=42)

random_search.fit(X_train, y_crop_train)
# Best Parameters: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 1.0}
# Get the best parameters and train the final model
best_xgb_params = random_search.best_params_
print("Best Parameters:", best_xgb_params)

final_xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss', **best_xgb_params)
final_xgb_model.fit(X_train, y_crop_train)

# Evaluate the model on the test set
y_crop_pred_xgb = final_xgb_model.predict(X_test)
print("XGBoost Model Performance:")
print(classification_report(y_crop_test, y_crop_pred_xgb))
print("Accuracy:", accuracy_score(y_crop_test, y_crop_pred_xgb))

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialize the Gradient Boosting Classifier
gb_model = GradientBoostingClassifier(random_state=42)

# Train the Gradient Boosting model on the training data
gb_model.fit(X_train, y_crop_train)

# Evaluate the Gradient Boosting model on the test set
y_crop_pred_gb = gb_model.predict(X_test)
print("Gradient Boosting Model Performance:")
print(classification_report(y_crop_test, y_crop_pred_gb))
print("Accuracy:", accuracy_score(y_crop_test, y_crop_pred_gb))

from sklearn.ensemble import VotingClassifier

ensemble_model = VotingClassifier(
    estimators=[
        ('random_forest', final_crop_model),
        ('xgboost', final_xgb_model),
        ('gradient_boosting', gb_model)
    ],
    voting='soft'  # Use 'soft' voting for probabilities
)

# Train the updated ensemble model on the training data
ensemble_model.fit(X_train, y_crop_train)

# Evaluate the updated ensemble model on the test set
y_ensemble_pred = ensemble_model.predict(X_test)
print("Updated Ensemble Model Performance:")
print(classification_report(y_crop_test, y_ensemble_pred))
print("Accuracy:", accuracy_score(y_crop_test, y_ensemble_pred))
import joblib
# Save the models and mappings to files
joblib.dump(ensemble_model, 'ensemble_model.pkl')
import joblib

def predict_fertilizer_and_crop(temp, potassium, phosphorus, nitrogen, humidity, moisture, soil_type):
    """
    Predicts the fertilizer and crop type based on input parameters.

    Parameters:
        temp (float): Temperature value (raw, not normalized).
        potassium (float): Potassium value (raw, not normalized).
        phosphorus (float): Phosphorus value (raw, not normalized).
        nitrogen (float): Nitrogen value (raw, not normalized).
        humidity (float): Humidity value (raw, not normalized).
        moisture (float): Moisture value (raw, not normalized).
        soil_type (int): Soil type value (numeric).

    Returns:
        dict: A dictionary containing the predicted crop name and fertilizer name.
    """
    # Load the ensemble model from the file
    ensemble_model = joblib.load('ensemble_model.pkl')

    # Convert soil type from string to numeric using the label encoder
    soil_type_numeric = soil_type

    # Create a single input sample
    input_data = pd.DataFrame([{
        'Temparature': temp,
        'Humidity': humidity,
        'Moisture': moisture,
        'Nitrogen': nitrogen,
        'Potassium': potassium,
        'Phosphorous': phosphorus,
        'Soil Type': soil_type_numeric
    }])

    # Normalize the numerical features using the scaler
    input_data[numerical_columns] = scaler.transform(input_data[numerical_columns])

    # Predict crop type using the ensemble model
    crop_prediction = ensemble_model.predict(input_data)[0]
    crop_name = crop_type_mapping[crop_prediction]

    # Predict fertilizer name
    fertilizer_prediction = fertilizer_model.predict(input_data)[0]
    fertilizer_name = fertilizer_name_mapping[fertilizer_prediction]

    return {
        'Predicted Crop Name': crop_name,
        'Predicted Fertilizer Name': fertilizer_name
    }
# Example usage
temp = 30.0  # Example temperature value (raw, not normalized)
potassium = 200.0  # Example potassium value (raw, not normalized) 
phosphorus = 50.0  # Example phosphorus value (raw, not normalized)
nitrogen = 100.0  # Example nitrogen value (raw, not normalized)
humidity = 70.0  # Example humidity value (raw, not normalized)
moisture = 30.0  # Example moisture value (raw, not normalized)
soil_type = 1  # Example soil type value (string)
# Call the prediction function
predictions = predict_fertilizer_and_crop(temp, potassium, phosphorus, nitrogen, humidity, moisture, soil_type)
print(predictions)